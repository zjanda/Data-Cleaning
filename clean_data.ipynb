{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from icecream import ic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    \"\"\"\n",
    "    Preprocess a list of strings.\n",
    "    :parameter\n",
    "        :param text: string - name of column containing text\n",
    "        :param flg_stemm: bool - whether stemming is to be applied\n",
    "        :param flg_lemm: bool - whether lemmitization is to be applied\n",
    "        :param lst_stopwords: list - list of stopwords to remove\n",
    "    :return\n",
    "        cleaned list of strings\n",
    "    \"\"\"\n",
    "    ## clean (convert to lowercase and remove punctuations and\n",
    "    # characters and then strip)\n",
    "    phrases = []\n",
    "    for phrase in tqdm(text):\n",
    "        phrase = re.sub(r'[^\\w\\s]', '', str(phrase).lower().strip())\n",
    "\n",
    "        ## Tokenize (convert from string to list)\n",
    "        lst_text = phrase.split()\n",
    "        ## remove Stopwords\n",
    "        if lst_stopwords is not None:\n",
    "            lst_text = [word for word in lst_text if word not in\n",
    "                        lst_stopwords]\n",
    "\n",
    "        ## Stemming (remove -ing, -ly, ...)\n",
    "        if flg_stemm:\n",
    "            ps = nltk.stem.porter.PorterStemmer()\n",
    "            lst_text = [ps.stem(word) for word in lst_text]\n",
    "\n",
    "        ## Lemmatization (convert the word into root word)\n",
    "        if flg_lemm:\n",
    "            lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "            lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "\n",
    "        ## back to string from list\n",
    "        phrase = \" \".join(lst_text)\n",
    "        phrases.append(phrase.split())\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zackj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\zackj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/omw-1.4')\n",
    "except LookupError:\n",
    "    nltk.download('omw-1.4')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 978/978 [00:00<00:00, 10302.62it/s]\n",
      "100%|██████████| 34115/34115 [00:02<00:00, 15893.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "good_list = pd.read_csv('data/Example_Technical_Skills.csv', header=1).to_numpy()\n",
    "raw_list = pd.read_csv('data/Raw_Skills_Dataset.csv', header=1).to_numpy()\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "good_list_p = preprocess_text(good_list, True, lst_stopwords=stop_words)\n",
    "raw_list_p = preprocess_text(raw_list, True, lst_stopwords=stop_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(raw_list_p): 34115, len(raw_list): 34115\n"
     ]
    },
    {
     "data": {
      "text/plain": "(34115, 34115)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(len(raw_list_p), len(raw_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| good_list[0]: array(['Oracle Instance Management & Strategy'], dtype=object)\n",
      "    good_list_p[0]: ['oracl', 'instanc', 'manag', 'strategi']\n",
      "ic| raw_list[0]: array(['seniority'], dtype=object)\n",
      "    raw_list_p[0]: ['senior']\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array(['seniority'], dtype=object), ['senior'])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(good_list[0], good_list_p[0])\n",
    "ic(raw_list[0], raw_list_p[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34115/34115 [00:03<00:00, 10728.01it/s]\n"
     ]
    }
   ],
   "source": [
    "def clean_data(data, text_filter):\n",
    "    \"\"\"\n",
    "    This function takes preprocessed (cleaned, stemmed, and lemmatized) data and filters it,\n",
    "    keeping track of the index of the words similar to those in the filter.\n",
    "    :parameter\n",
    "        :param data: 2D List of preprocessed word phrases to be filtered\n",
    "        :param text_filter: 2D List of acceptable rooted word phrases (each word in a phrase is a root)\n",
    "    :return:\n",
    "        1D List of indices that passed the filter\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    break_flag = False\n",
    "    for i in tqdm(range(len(data))):\n",
    "        for word in data[i]: # for 'words' in ['words', 'in', 'phrase']\n",
    "            for j, phrase in enumerate(text_filter): # for ['phrases', 'in', 'the''] in [['phrases', 'in', 'the''], ['list', 'of'], ['tech', 'skills']]\n",
    "                if word in phrase: # if 'words' in ['phrases', 'in', 'the']\n",
    "                    indices.append(i)\n",
    "                    break_flag = True\n",
    "                    break\n",
    "            if break_flag:\n",
    "                break_flag = False\n",
    "                break\n",
    "    return indices\n",
    "\n",
    "tech_skill_indices = clean_data(raw_list_p, good_list_p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20110\n"
     ]
    }
   ],
   "source": [
    "print(len(tech_skill_indices))\n",
    "cleaned_list = raw_list[tech_skill_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "CSD_df = pd.DataFrame(cleaned_list, columns=['Extracted Skills'])\n",
    "CSD_df.to_csv('data/Cleaned_Skills_Dataset.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}